{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76ebe6d7",
   "metadata": {},
   "source": [
    "# Music Emotion Recognition\n",
    "This notebook provides the code for implementing a BERT classiier \n",
    "\n",
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73cce86a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T19:57:35.774827Z",
     "iopub.status.busy": "2022-02-02T19:57:35.773338Z",
     "iopub.status.idle": "2022-02-02T19:58:25.190118Z",
     "shell.execute_reply": "2022-02-02T19:58:25.189477Z",
     "shell.execute_reply.started": "2022-02-02T17:01:25.429004Z"
    },
    "papermill": {
     "duration": 49.470062,
     "end_time": "2022-02-02T19:58:25.190293",
     "exception": false,
     "start_time": "2022-02-02T19:57:35.720231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install music21 miditoolkit miditok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f5b767b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --user torch==1.7.0 torchvision==0.8.1 -f https://download.pytorch.org/whl/cu102/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dac3b311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "623e6006",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-02-02T19:58:25.393046Z",
     "iopub.status.busy": "2022-02-02T19:58:25.392169Z",
     "iopub.status.idle": "2022-02-02T19:58:34.251523Z",
     "shell.execute_reply": "2022-02-02T19:58:34.250961Z",
     "shell.execute_reply.started": "2022-02-02T17:02:12.062192Z"
    },
    "papermill": {
     "duration": 8.962224,
     "end_time": "2022-02-02T19:58:34.251664",
     "exception": false,
     "start_time": "2022-02-02T19:58:25.289440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\newpydisser\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from io import open\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import time\n",
    "from miditok import get_midi_programs, REMI, MIDILike\n",
    "from miditoolkit import MidiFile\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n",
    "from transformers import BertForSequenceClassification, BertConfig, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e2dade1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92a58fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5681736",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d70c676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b00bcb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed\n",
    "# seed = 22\n",
    "# torch.manual_seed(seed)\n",
    "# torch.cuda.manual_seed(seed)\n",
    "# torch.cuda.manual_seed_all(seed)\n",
    "# np.random.seed(seed)\n",
    "# torch.backends.cudnn.benchmark = False\n",
    "# torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cd2282",
   "metadata": {},
   "source": [
    "## Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "528f24ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T19:58:34.992588Z",
     "iopub.status.busy": "2022-02-02T19:58:34.991885Z",
     "iopub.status.idle": "2022-02-02T19:58:35.024130Z",
     "shell.execute_reply": "2022-02-02T19:58:35.024622Z",
     "shell.execute_reply.started": "2022-02-01T19:55:02.159239Z"
    },
    "papermill": {
     "duration": 0.199123,
     "end_time": "2022-02-02T19:58:35.024817",
     "exception": false,
     "start_time": "2022-02-02T19:58:34.825694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticks per beat: 384\n",
       "max tick: 46051\n",
       "tempo changes: 1\n",
       "time sig: 1\n",
       "key sig: 0\n",
       "markers: 0\n",
       "lyrics: False\n",
       "instruments: 1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how a midi file looks like\n",
    "midi = MidiFile('archive/EMOPIA_1.0 (1)/EMOPIA_1.0/midis/Q1__8v0MFBZoco_0.mid')\n",
    "midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2401ae07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Instrument(program=0, is_drum=False, name=\"\")]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for now, we will only be using for piano right since it determines the melody\n",
    "midi.instruments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2875ef2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file path to the MIDI files\n",
    "files_paths = list(glob.glob('archive/EMOPIA_1.0 (1)/EMOPIA_1.0/midis/*.mid'))\n",
    "# reading labels\n",
    "labels_df = pd.read_csv('archive/EMOPIA_1.0 (1)/EMOPIA_1.0/label.csv')\n",
    "labels_df = list(labels_df['4Q'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55496aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import muspy\n",
    "\n",
    "def return_range(music):\n",
    "    h = 0\n",
    "    l = 127\n",
    "    for track in music.tracks:\n",
    "        for note in track.notes:\n",
    "            if note.pitch > h:\n",
    "                h = note.pitch\n",
    "            if note.pitch < l:\n",
    "                l = note.pitch\n",
    "    return [h, l]\n",
    "\n",
    "tempos = []\n",
    "pitches = []\n",
    "\n",
    "for file in files_paths:\n",
    "    music = muspy.read_midi(file)\n",
    "    tempos.append(music.tempos[0].qpm)\n",
    "    pitches.extend(return_range(music))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cf5693f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unique tempos found in the dataset are:  {120.0}\n",
      "minimum pitch found 22\n",
      "maximum pitch found 105\n"
     ]
    }
   ],
   "source": [
    "print(\"The unique tempos found in the dataset are: \", set(tempos))\n",
    "print('minimum pitch found', min(pitches))\n",
    "print('maximum pitch found', max(pitches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1626dd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_range = range(22, 105)\n",
    "additional_tokens = {'Chord': True, 'Rest': True, 'Tempo': True, 'Program': False,\n",
    "                     'rest_range': (2, 4),  # (half, 8 beats)\n",
    "                     'nb_tempos': 32,  # nb of tempo bins\n",
    "                     'tempo_range': (100, 140),\n",
    "                     'TimeSignature':None}  # (min, max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54418a08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T19:58:35.213504Z",
     "iopub.status.busy": "2022-02-02T19:58:35.212909Z",
     "iopub.status.idle": "2022-02-02T19:59:00.573774Z",
     "shell.execute_reply": "2022-02-02T19:59:00.573213Z",
     "shell.execute_reply.started": "2022-02-02T17:04:02.153938Z"
    },
    "papermill": {
     "duration": 25.455698,
     "end_time": "2022-02-02T19:59:00.573925",
     "exception": false,
     "start_time": "2022-02-02T19:58:35.118227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a list of notes\n",
    "\n",
    "def load_files(files_paths, encoder = REMI(additional_tokens)):\n",
    "    assert len(files_paths) > 0\n",
    "    notes = []\n",
    "\n",
    "\n",
    "    for file in files_paths:\n",
    "        # file_name = os.path.basename(file)\n",
    "\n",
    "        # read the MIDI file\n",
    "        midi = MidiFile(file)\n",
    "\n",
    "        # Converts MIDI to tokens\n",
    "        tokens = encoder.midi_to_tokens(midi)\n",
    "        \n",
    "        # The EMOPIA dataset has midi files with only one instrument, i.e. the piano \n",
    "        # hence we just add those tokens\n",
    "        # print(tokens)\n",
    "        notes.append(tokens[0])\n",
    "\n",
    "    return notes, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69917162",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes, midi_enc = load_files(files_paths, MIDILike(pitch_range, additional_tokens = additional_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3d9b808",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T19:59:01.757463Z",
     "iopub.status.busy": "2022-02-02T19:59:01.756729Z",
     "iopub.status.idle": "2022-02-02T19:59:01.759444Z",
     "shell.execute_reply": "2022-02-02T19:59:01.759843Z",
     "shell.execute_reply.started": "2022-02-02T17:06:14.781954Z"
    },
    "papermill": {
     "duration": 0.098923,
     "end_time": "2022-02-02T19:59:01.759981",
     "exception": false,
     "start_time": "2022-02-02T19:59:01.661058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 317 unique tokens in the files\n"
     ]
    }
   ],
   "source": [
    "print(\"There are\",len(midi_enc.vocab),\"unique tokens in the files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "627e7f4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T19:59:02.145710Z",
     "iopub.status.busy": "2022-02-02T19:59:02.144060Z",
     "iopub.status.idle": "2022-02-02T19:59:02.146289Z",
     "shell.execute_reply": "2022-02-02T19:59:02.146719Z",
     "shell.execute_reply.started": "2022-02-02T17:53:06.340581Z"
    },
    "papermill": {
     "duration": 0.101832,
     "end_time": "2022-02-02T19:59:02.146867",
     "exception": false,
     "start_time": "2022-02-02T19:59:02.045035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a dataset corpus from the notes and labels\n",
    "class Corpus(Dataset):\n",
    "    def __init__(self, notes, labels, encoder, seq_length):\n",
    "        self.encoder = encoder\n",
    "        self.seq_len = seq_length\n",
    "\n",
    "        \n",
    "        self.xtrain, self.ytrain= self.tokenize(notes, labels)\n",
    "        # self.xtest, self.ytest, _, _ = self.tokenize(ntest, ltest)\n",
    "        # self.xvalid = self.tokenize(ntest, ltest)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.encoder.vocab)\n",
    "\n",
    "    def len_dataset(self):\n",
    "        return len(self.xtrain)\n",
    "    \n",
    "    def __getitem__(self, index, ):\n",
    "        return self.xtrain[index], self.ytrain[index]\n",
    "    \n",
    "    def tokenize(self, notes, labels):\n",
    "        assert len(notes) > 0\n",
    "        assert len(labels) > 0\n",
    "\n",
    "        # create a set of notes\n",
    "        # they should all be padded to have sequence of len seq_len\n",
    "        songss = []\n",
    "        target = []\n",
    "\n",
    "        for song, label in zip(notes, labels):\n",
    "            song = torch.tensor(song).type(torch.int64)\n",
    "            songs = list(song.split(self.seq_len))\n",
    "\n",
    "            for i in range(len(songs)):\n",
    "                # removing sequences that have < seq len/4 tokens\n",
    "                if len(songs[i]) < self.seq_len/4:\n",
    "                    del songs[i]\n",
    "                    continue\n",
    "                target.append(label-1)\n",
    "            songss.extend(songs)\n",
    "        \n",
    "        # padding songs to be of same length\n",
    "        data = pad_sequence(songss)\n",
    "        data = data.T\n",
    "        target = torch.LongTensor(target)\n",
    "\n",
    "        # corpus = []\n",
    "\n",
    "        # corpus = torch.stack(corpus)\n",
    "\n",
    "        # creates the range of each type of token\n",
    "        # for eg. family is [0, 2, 3]\n",
    "        \n",
    "        \n",
    "        # token_ranges = [corpus[:,:,i].squeeze().unique() for i in range(7)]\n",
    "        \n",
    "        # # creates a reverse dictionary for each token\n",
    "        # # for eg. family is {0: 0, 2: 1, 3: 2}\n",
    "        # token_dicts = [dict(zip(tokens.tolist(), range(len(tokens)))) for tokens in token_ranges]\n",
    "\n",
    "        # data = corpus.clone().detach()\n",
    "        # for i in range(len(corpus)):\n",
    "        #     for k in range(7):\n",
    "        #         data[i,:,k] = torch.tensor([token_dicts[k][l.item()] for l in corpus[i,:,k]])\n",
    "\n",
    "        # data = new_corpus[:,:self.seq_len - 1, :]\n",
    "        # target = new_corpus[:,1:self.seq_len, :]\n",
    "            \n",
    "\n",
    "        # converting all the tokens in each type to new values:\n",
    "        return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0072540",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T19:59:02.350085Z",
     "iopub.status.busy": "2022-02-02T19:59:02.349327Z",
     "iopub.status.idle": "2022-02-02T19:59:02.547361Z",
     "shell.execute_reply": "2022-02-02T19:59:02.547868Z",
     "shell.execute_reply.started": "2022-02-02T17:53:07.695073Z"
    },
    "papermill": {
     "duration": 0.308022,
     "end_time": "2022-02-02T19:59:02.548041",
     "exception": false,
     "start_time": "2022-02-02T19:59:02.240019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ntrain, ntest, ltrain, ltest = train_test_split(notes, labels_df, test_size=0.3, random_state=42, shuffle=True, stratify=labels_df)\n",
    "train_corpus = Corpus(ntrain, ltrain, midi_enc, 50)\n",
    "val_corpus = Corpus(ntest, ltest, midi_enc, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35102c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape: torch.Size([15104, 50])\n",
      "test data shape: torch.Size([6560, 50])\n",
      "train data shape: torch.Size([15104])\n",
      "test data shape: torch.Size([6560])\n"
     ]
    }
   ],
   "source": [
    "xtest = val_corpus.xtrain\n",
    "xtrain = train_corpus.xtrain\n",
    "# ytest = val_corpus.ytrain\n",
    "# ytrain = train_corpus.ytrain\n",
    "\n",
    "\n",
    "# train_emo = corpus.ytrain.to(device)\n",
    "# val_emo = corpus.yvalid.to(device)\n",
    "\n",
    "print(\"train data shape:\", train_corpus.xtrain.shape)\n",
    "print(\"test data shape:\", val_corpus.xtrain.shape)\n",
    "print(\"train data shape:\", train_corpus.ytrain.shape)\n",
    "print(\"test data shape:\", val_corpus.ytrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ddd8310a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "# creating a dataloader\n",
    "train_dataloader = DataLoader(\n",
    "    train_corpus,\n",
    "    sampler=SequentialSampler(xtrain),\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    val_corpus,\n",
    "    sampler=SequentialSampler(xtest),\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1e8bdf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T19:59:02.746806Z",
     "iopub.status.busy": "2022-02-02T19:59:02.745183Z",
     "iopub.status.idle": "2022-02-02T19:59:02.749838Z",
     "shell.execute_reply": "2022-02-02T19:59:02.749418Z",
     "shell.execute_reply.started": "2022-02-02T17:53:08.825871Z"
    },
    "papermill": {
     "duration": 0.104443,
     "end_time": "2022-02-02T19:59:02.749958",
     "exception": false,
     "start_time": "2022-02-02T19:59:02.645515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are total 1078 songs and a total of 21664 sequences extracted\n"
     ]
    }
   ],
   "source": [
    "print(\"There are total\",len(notes), \"songs and a total of\", xtrain.shape[0] + xtest.shape[0], \"sequences extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1643dbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 317 unique tokens\n"
     ]
    }
   ],
   "source": [
    "print(\"There are\",len(train_corpus), \"unique tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f054c0b7",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "\n",
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86a292fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of the model\n",
    "ntokens = len(train_corpus)\n",
    "emsize = 256\n",
    "\n",
    "# parameters for the transformers\n",
    "nhid = 252\n",
    "\n",
    "# dropout\n",
    "dropout = 0.4\n",
    "\n",
    "# learning rates for each\n",
    "lr = 0.001\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c3f68f",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84eb2888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from \n",
    "# https://github.com/wazenmai/MIDI-BERT/blob/main/MidiBERT/remi/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e37bf0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self, ntokens, nhid=252, max_len = 50, vocab_size = ntokens, num_hidden_layers = 4, num_attention_heads = 6):\n",
    "        super().__init__()\n",
    "\n",
    "        config = BertConfig(vocab_size = vocab_size, num_hidden_layers = num_hidden_layers, num_attention_heads = num_attention_heads, max_position_embeddings=max_len, position_embedding_type='relative_key_query', hidden_size=nhid)     \n",
    "        self.d_model = nhid\n",
    "        self.nhid = nhid\n",
    "\n",
    "        self.n_token = ntokens\n",
    "        self.emb_size = 256\n",
    "        \n",
    "        # creates an embedding of the tokens\n",
    "        self.embedding = nn.Embedding(self.n_token, self.emb_size) \n",
    "\n",
    "        # passing through a linear layer, to reduce the features to the dimension of the model \n",
    "        self.in_linear = nn.Linear(self.emb_size, self.d_model)\n",
    "        \n",
    "        # pass through a BERT model\n",
    "        self.bert = BertModel(config)\n",
    "\n",
    "        # output to 4 classes\n",
    "        self.out_linear = nn.Linear(self.d_model, 4)\n",
    "\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        # create embedding\n",
    "        x = x.to(device)\n",
    "        if attn_mask != None:\n",
    "            attn_mask = attn_mask.to(device)\n",
    "        x = self.embedding(x) * math.sqrt(self.d_model)\n",
    "        # linear layer\n",
    "        x = self.in_linear(x)\n",
    "        \n",
    "        x = self.bert(inputs_embeds=x, attention_mask=attn_mask, output_hidden_states=True)\n",
    "        \n",
    "        x = x.hidden_states[-1]\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.out_linear(x)\n",
    "        # print(x.shape)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b50ece0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERTClassifier(\n",
       "  (embedding): Embedding(317, 256)\n",
       "  (in_linear): Linear(in_features=256, out_features=252, bias=True)\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(317, 252, padding_idx=0)\n",
       "      (position_embeddings): Embedding(50, 252)\n",
       "      (token_type_embeddings): Embedding(2, 252)\n",
       "      (LayerNorm): LayerNorm((252,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=252, out_features=252, bias=True)\n",
       "              (key): Linear(in_features=252, out_features=252, bias=True)\n",
       "              (value): Linear(in_features=252, out_features=252, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (distance_embedding): Embedding(99, 42)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=252, out_features=252, bias=True)\n",
       "              (LayerNorm): LayerNorm((252,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=252, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=252, bias=True)\n",
       "            (LayerNorm): LayerNorm((252,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=252, out_features=252, bias=True)\n",
       "              (key): Linear(in_features=252, out_features=252, bias=True)\n",
       "              (value): Linear(in_features=252, out_features=252, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (distance_embedding): Embedding(99, 42)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=252, out_features=252, bias=True)\n",
       "              (LayerNorm): LayerNorm((252,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=252, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=252, bias=True)\n",
       "            (LayerNorm): LayerNorm((252,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=252, out_features=252, bias=True)\n",
       "              (key): Linear(in_features=252, out_features=252, bias=True)\n",
       "              (value): Linear(in_features=252, out_features=252, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (distance_embedding): Embedding(99, 42)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=252, out_features=252, bias=True)\n",
       "              (LayerNorm): LayerNorm((252,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=252, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=252, bias=True)\n",
       "            (LayerNorm): LayerNorm((252,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=252, out_features=252, bias=True)\n",
       "              (key): Linear(in_features=252, out_features=252, bias=True)\n",
       "              (value): Linear(in_features=252, out_features=252, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (distance_embedding): Embedding(99, 42)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=252, out_features=252, bias=True)\n",
       "              (LayerNorm): LayerNorm((252,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=252, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=252, bias=True)\n",
       "            (LayerNorm): LayerNorm((252,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=252, out_features=252, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (out_linear): Linear(in_features=252, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BERTClassifier(ntokens, nhid=nhid)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fec50c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_paras(model):\n",
    "    # compute only trainable params\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fff1df32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7551384 parameters in the model\n"
     ]
    }
   ],
   "source": [
    "print(\"There are\",network_paras(model),\"parameters in the model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8af7b94",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8bd5647b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "885307c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "472"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e3e6213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_token = midi_enc.vocab.event_to_token['PAD_None']\n",
    "pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "837cd3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200 (17s): Training Loss: 1.152, Training Accuracy: 0.455\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ms374\\Downloads\\bert_mer_model.ipynb Cell 39'\u001b[0m in \u001b[0;36m<cell line: 57>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ms374/Downloads/bert_mer_model.ipynb#ch0000038?line=51'>52</a>\u001b[0m         writer\u001b[39m.\u001b[39madd_scalar(\u001b[39m\"\u001b[39m\u001b[39mTraining Accuracy\u001b[39m\u001b[39m\"\u001b[39m, accuracies[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], epoch)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ms374/Downloads/bert_mer_model.ipynb#ch0000038?line=53'>54</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mepochs\u001b[39m}\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mint\u001b[39m(time() \u001b[39m-\u001b[39m start)\u001b[39m}\u001b[39;00m\u001b[39ms):\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ms374/Downloads/bert_mer_model.ipynb#ch0000038?line=54'>55</a>\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m Training Loss: \u001b[39m\u001b[39m{\u001b[39;00mlosses[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ms374/Downloads/bert_mer_model.ipynb#ch0000038?line=55'>56</a>\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m Training Accuracy: \u001b[39m\u001b[39m{\u001b[39;00maccuracies[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ms374/Downloads/bert_mer_model.ipynb#ch0000038?line=56'>57</a>\u001b[0m train()\n",
      "\u001b[1;32mc:\\Users\\ms374\\Downloads\\bert_mer_model.ipynb Cell 39'\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ms374/Downloads/bert_mer_model.ipynb#ch0000038?line=27'>28</a>\u001b[0m attn_mask \u001b[39m=\u001b[39m  (xtrain \u001b[39m!=\u001b[39m pad_token)\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mto(device)  \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ms374/Downloads/bert_mer_model.ipynb#ch0000038?line=29'>30</a>\u001b[0m y \u001b[39m=\u001b[39m model(xtrain, attn_mask)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ms374/Downloads/bert_mer_model.ipynb#ch0000038?line=31'>32</a>\u001b[0m learning \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(y\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39mdetach(), axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ms374/Downloads/bert_mer_model.ipynb#ch0000038?line=32'>33</a>\u001b[0m learning \u001b[39m=\u001b[39m learning\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mfloat)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ms374/Downloads/bert_mer_model.ipynb#ch0000038?line=34'>35</a>\u001b[0m acc \u001b[39m=\u001b[39m accuracy_score(ytrain, learning)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "model.train()\n",
    "crit = nn.CrossEntropyLoss(reduction='mean')\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "\n",
    "def train():\n",
    "    epochs = 200\n",
    "    batches = len(train_dataloader)\n",
    "\n",
    "    losses, accuracies = [], []\n",
    "    start = time()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        model.zero_grad()\n",
    "        \n",
    "        total_loss, total_acc  = 0, 0\n",
    "\n",
    "        for bidx, (xtrain, ytrain)  in enumerate(train_dataloader): \n",
    "            optim.zero_grad()\n",
    "            xtrain.to(device)\n",
    "            ytrain.to(device)\n",
    "\n",
    "            # loss_mask = torch.ones(xtrain.size(0), (xtrain.size(1)))\n",
    "\n",
    "            attn_mask =  (xtrain != pad_token).float().to(device)  \n",
    "\n",
    "            y = model(xtrain, attn_mask)\n",
    "\n",
    "            learning = np.argmax(y.cpu().detach(), axis=-1)\n",
    "            learning = learning.type(torch.float)\n",
    "\n",
    "            acc = accuracy_score(ytrain, learning)\n",
    "            # print(target.shape, learning.shape)\n",
    "    \n",
    "            # calculate losses\n",
    "            loss = crit(y.cpu(), ytrain.cpu())\n",
    "            \n",
    "            total_loss += loss\n",
    "            total_acc += acc\n",
    "        \n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 3.0)\n",
    "            optim.step()\n",
    "\n",
    "        losses.append(total_loss/ batches)\n",
    "        accuracies.append(total_acc / batches)\n",
    "\n",
    "        writer.add_scalar(\"Training Loss\", losses[-1], epoch)\n",
    "        writer.add_scalar(\"Training Accuracy\", accuracies[-1], epoch)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs} ({int(time() - start)}s):\"\n",
    "              f\" Training Loss: {losses[-1]:.3f},\"\n",
    "              f\" Training Accuracy: {accuracies[-1]:.3f}\")\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3516a59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ms374\\Downloads\\bert_mer_model.ipynb Cell 40'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ms374/Downloads/bert_mer_model.ipynb#ch0000039?line=0'>1</a>\u001b[0m \u001b[39m# Print model's state_dict\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ms374/Downloads/bert_mer_model.ipynb#ch0000039?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mModel\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms state_dict:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ms374/Downloads/bert_mer_model.ipynb#ch0000039?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m param_tensor \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mstate_dict():\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ms374/Downloads/bert_mer_model.ipynb#ch0000039?line=3'>4</a>\u001b[0m     \u001b[39mprint\u001b[39m(param_tensor, \u001b[39m\"\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m, model\u001b[39m.\u001b[39mstate_dict()[param_tensor]\u001b[39m.\u001b[39msize())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f094754",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './models/bert_mer_final.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032adee0",
   "metadata": {},
   "source": [
    "## Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "44d86bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Testing Loss: 0.989, Testing Accuracy: 0.591\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "model.eval()\n",
    "cms = torch.zeros((4,4))\n",
    "def eval(cms):\n",
    "    batches = len(val_dataloader)\n",
    "        \n",
    "    total_loss, total_acc  = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for bidx, (xtest, ytest)  in enumerate(val_dataloader): \n",
    "            xtest.to(device)\n",
    "            ytest.to(device)\n",
    "\n",
    "            attn_mask =  (xtest != pad_token).float().to(device)  \n",
    "\n",
    "            y = model(xtest, attn_mask)\n",
    "\n",
    "            y_pred = np.argmax(y.cpu().detach(), axis=-1)\n",
    "            y_pred = y_pred.type(torch.float)\n",
    "\n",
    "            acc = accuracy_score(ytest, y_pred)\n",
    "\n",
    "            cm = confusion_matrix(ytest, y_pred, labels=range(4), normalize='true')\n",
    "\n",
    "            cms += cm\n",
    "\n",
    "            loss = crit(y.cpu(), ytest.cpu())\n",
    "            \n",
    "            total_loss += loss\n",
    "            total_acc += acc\n",
    "\n",
    "\n",
    "    total_loss = (total_loss/ batches)\n",
    "    total_acc = (total_acc / batches)\n",
    "\n",
    "    \n",
    "    print(f\" Testing Loss: {total_loss:.3f},\"\n",
    "          f\" Testing Accuracy: {total_acc:.3f}\")\n",
    "\n",
    "    return cms\n",
    "cms = eval(cms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aa1926a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[62.6556, 32.3889,  1.3749,  5.5807],\n",
       "        [30.9377, 76.3917,  4.3522,  7.3184],\n",
       "        [17.2699,  4.4761, 26.4841, 43.7700],\n",
       "        [14.9345,  2.4288,  9.1659, 83.4708]], dtype=torch.float64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "39007a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 275,
       "width": 266
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.imshow(cms, interpolation='nearest')\n",
    "plt.title('Confusion Matrix for BERT MER', fontsize=10)\n",
    "labels = ['Q'+str(i+1) for i in range(4)]\n",
    "tick_marks = np.arange(len(labels))\n",
    "plt.xticks(tick_marks, labels, fontsize=10)\n",
    "plt.yticks(tick_marks, labels, fontsize=10)\n",
    "\n",
    "# print('Confusion matrix, without normalization')\n",
    "\n",
    "thresh = cms.max() / 2.\n",
    "for i, j in itertools.product(range(cms.shape[0]), range(cms.shape[1])):\n",
    "    plt.text(j, i, format(cms[i, j], '.2f'),\n",
    "                horizontalalignment=\"center\",\n",
    "                color=\"white\" if cms[i, j] > thresh else \"black\",\n",
    "                fontsize=10)\n",
    "\n",
    "plt.ylabel('True label', fontsize=10)\n",
    "plt.xlabel('Predicted label', fontsize=10)\n",
    "plt.savefig(\"bert_classification_58.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5a6d2d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7cf5665",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ca647571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MidiTransGAN(\n",
       "  (generator): Generator(\n",
       "    (criterion): CrossEntropyLoss()\n",
       "    (embedding_family): Embedding(3, 32)\n",
       "    (embedding_bar): Embedding(35, 128)\n",
       "    (embedding_pitch): Embedding(85, 512)\n",
       "    (embedding_velocity): Embedding(32, 128)\n",
       "    (embedding_duration): Embedding(66, 256)\n",
       "    (embedding_chord): Embedding(16, 64)\n",
       "    (embedding_rest): Embedding(7, 64)\n",
       "    (embedding_tempo): Embedding(3, 32)\n",
       "    (embedding_emotion): Embedding(4, 512)\n",
       "    (in_linear): Linear(in_features=1728, out_features=256, bias=True)\n",
       "    (pos_encoder): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.4, inplace=False)\n",
       "    )\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.4, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.4, inplace=False)\n",
       "          (dropout2): Dropout(p=0.4, inplace=False)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.4, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.4, inplace=False)\n",
       "          (dropout2): Dropout(p=0.4, inplace=False)\n",
       "        )\n",
       "        (2): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.4, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.4, inplace=False)\n",
       "          (dropout2): Dropout(p=0.4, inplace=False)\n",
       "        )\n",
       "        (3): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.4, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.4, inplace=False)\n",
       "          (dropout2): Dropout(p=0.4, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (project_family): Linear(in_features=256, out_features=3, bias=True)\n",
       "    (project_bar): Linear(in_features=256, out_features=35, bias=True)\n",
       "    (project_pitch): Linear(in_features=256, out_features=85, bias=True)\n",
       "    (project_velocity): Linear(in_features=256, out_features=32, bias=True)\n",
       "    (project_duration): Linear(in_features=256, out_features=66, bias=True)\n",
       "    (project_chord): Linear(in_features=256, out_features=16, bias=True)\n",
       "    (project_rest): Linear(in_features=256, out_features=7, bias=True)\n",
       "    (project_tempo): Linear(in_features=256, out_features=3, bias=True)\n",
       "    (project_emo): Linear(in_features=256, out_features=4, bias=True)\n",
       "    (proj_cat): Linear(in_features=288, out_features=256, bias=True)\n",
       "  )\n",
       "  (discriminator): Discriminator(\n",
       "    (embedding_family): Embedding(3, 32)\n",
       "    (embedding_bar): Embedding(35, 128)\n",
       "    (embedding_pitch): Embedding(85, 512)\n",
       "    (embedding_velocity): Embedding(32, 128)\n",
       "    (embedding_duration): Embedding(66, 256)\n",
       "    (embedding_chord): Embedding(16, 64)\n",
       "    (embedding_rest): Embedding(7, 64)\n",
       "    (embedding_tempo): Embedding(3, 32)\n",
       "    (embedding_emotion): Embedding(4, 512)\n",
       "    (linear): Linear(in_features=1728, out_features=256, bias=True)\n",
       "    (pos_encoder): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.4, inplace=False)\n",
       "    )\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.4, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.4, inplace=False)\n",
       "          (dropout2): Dropout(p=0.4, inplace=False)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.4, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.4, inplace=False)\n",
       "          (dropout2): Dropout(p=0.4, inplace=False)\n",
       "        )\n",
       "        (2): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.4, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.4, inplace=False)\n",
       "          (dropout2): Dropout(p=0.4, inplace=False)\n",
       "        )\n",
       "        (3): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.4, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.4, inplace=False)\n",
       "          (dropout2): Dropout(p=0.4, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (classifier): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       "  (criterion): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BERTClassifier(ntokens)\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load('./models/bert_mer.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "46dccd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard\n",
    "# https://pytorch.org/tutorials/recipes/recipes/tensorboard_with_pytorch.html?msclkid=ce0b97e5b41911ec9d2e71bb3c7d0f90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0d551adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install muspy\n",
    "import muspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fe6bd16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "| Generated 200 notes\n",
      "1\n",
      "| Generated 200 notes\n",
      "1\n",
      "| Generated 200 notes\n",
      "1\n",
      "| Generated 200 notes\n"
     ]
    }
   ],
   "source": [
    "# TODO: fix the generate sample function to handle batch size = 1\n",
    "sequences = []\n",
    "for emo in range(0,4):\n",
    "    n_generate = 200\n",
    "    temperature = 1\n",
    "    log_interval = 4000 # interval between logs\n",
    "\n",
    "    notes = []\n",
    "    for token in ntokens[:-1]:\n",
    "        # print(token)\n",
    "        notes.append(torch.randint(token, (1, 2), dtype=torch.long).to(device))\n",
    "    \n",
    "\n",
    "    emotions = torch.full((1, 2), emo).to(device)\n",
    "    \n",
    "    notes.append(emotions)\n",
    "\n",
    "    # stacked input\n",
    "    inputs = torch.stack(notes, dim=-1)\n",
    "    print(len(inputs))\n",
    "        \n",
    "    src_mask = generate_square_subsequent_mask(len(inputs)).to(device)\n",
    "\n",
    "    output = gan.generate_samples(latent_vec=inputs, emotion=emo, num=n_generate, src_mask=None, display=False)\n",
    "\n",
    "    for i in range(len(output)):\n",
    "        # output[i,:,0] = torch.tensor([tokens_to_raw[0][l] for l in output[i,:,0]])\n",
    "        for k in range(0,8):\n",
    "            output[i,:,k] = torch.tensor([tokens_to_raw[k][l] for l in output[i,:,k]])\n",
    "    # print(output)\n",
    "    # if i % log_interval == 0:\n",
    "    print('| Generated {} notes'.format(n_generate))\n",
    "    sequences.append([output[:,2:,:-1].squeeze().cpu().tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "baf8e2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import muspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c2359ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[[2, 199, 34, 101, 179, 230, 0, 261],\n",
       "   [2, 205, 72, 113, 165, 221, 243, 261],\n",
       "   [3, 197, 72, 100, 148, 222, 243, 261],\n",
       "   [2, 192, 12, 92, 158, 229, 241, 261],\n",
       "   [2, 189, 81, 95, 170, 227, 0, 261],\n",
       "   [2, 0, 64, 93, 183, 225, 238, 261],\n",
       "   [2, 207, 67, 102, 124, 232, 240, 0],\n",
       "   [2, 208, 69, 114, 148, 223, 240, 244],\n",
       "   [2, 210, 57, 109, 165, 223, 241, 261],\n",
       "   [2, 208, 61, 95, 140, 225, 238, 244],\n",
       "   [2, 191, 33, 108, 177, 221, 0, 244],\n",
       "   [2, 190, 20, 103, 148, 229, 239, 244],\n",
       "   [2, 209, 74, 92, 142, 231, 239, 0],\n",
       "   [2, 208, 68, 111, 150, 231, 241, 0],\n",
       "   [2, 191, 51, 111, 126, 230, 238, 244],\n",
       "   [2, 215, 25, 92, 172, 227, 241, 261],\n",
       "   [2, 1, 57, 96, 135, 229, 238, 261],\n",
       "   [3, 189, 83, 110, 155, 221, 242, 261],\n",
       "   [2, 213, 7, 96, 185, 232, 243, 261],\n",
       "   [3, 195, 18, 98, 174, 221, 243, 261],\n",
       "   [2, 219, 51, 105, 143, 220, 240, 244],\n",
       "   [3, 198, 9, 114, 138, 221, 242, 261],\n",
       "   [2, 0, 71, 115, 125, 231, 241, 261],\n",
       "   [3, 196, 37, 95, 143, 222, 242, 261],\n",
       "   [2, 197, 35, 112, 158, 220, 243, 244],\n",
       "   [2, 208, 28, 114, 170, 232, 242, 261],\n",
       "   [2, 201, 82, 94, 127, 233, 240, 244],\n",
       "   [2, 1, 63, 110, 139, 223, 243, 244],\n",
       "   [2, 1, 41, 105, 123, 223, 243, 261],\n",
       "   [3, 189, 72, 119, 146, 234, 241, 261],\n",
       "   [2, 197, 37, 97, 168, 221, 243, 261],\n",
       "   [2, 192, 7, 94, 159, 228, 243, 0],\n",
       "   [3, 190, 38, 92, 141, 224, 240, 261],\n",
       "   [2, 191, 40, 93, 144, 228, 243, 244],\n",
       "   [2, 192, 73, 108, 150, 232, 240, 0],\n",
       "   [3, 193, 30, 94, 142, 229, 239, 261],\n",
       "   [2, 203, 27, 92, 162, 230, 243, 0],\n",
       "   [2, 187, 60, 92, 152, 224, 241, 261],\n",
       "   [3, 188, 74, 103, 169, 222, 243, 261],\n",
       "   [2, 217, 8, 115, 139, 234, 243, 0],\n",
       "   [2, 211, 9, 114, 149, 220, 242, 261],\n",
       "   [3, 198, 0, 102, 161, 227, 240, 261],\n",
       "   [3, 215, 35, 96, 160, 231, 243, 261],\n",
       "   [3, 212, 19, 112, 186, 228, 243, 261],\n",
       "   [3, 204, 25, 95, 173, 231, 241, 261],\n",
       "   [2, 215, 32, 110, 141, 228, 238, 261],\n",
       "   [2, 190, 12, 104, 182, 221, 239, 261],\n",
       "   [2, 190, 63, 119, 135, 232, 241, 261],\n",
       "   [3, 197, 49, 90, 173, 224, 239, 261],\n",
       "   [2, 206, 30, 105, 156, 231, 240, 244],\n",
       "   [2, 206, 60, 91, 126, 229, 242, 244],\n",
       "   [2, 197, 56, 102, 129, 229, 241, 0],\n",
       "   [3, 208, 50, 113, 183, 233, 242, 261],\n",
       "   [2, 218, 25, 102, 179, 228, 239, 244],\n",
       "   [2, 206, 32, 118, 139, 226, 0, 261],\n",
       "   [2, 206, 37, 103, 156, 228, 238, 244],\n",
       "   [2, 216, 83, 115, 143, 220, 240, 0],\n",
       "   [2, 218, 33, 107, 135, 233, 243, 261],\n",
       "   [2, 219, 73, 91, 175, 234, 243, 261],\n",
       "   [3, 211, 55, 105, 180, 229, 239, 261],\n",
       "   [2, 196, 55, 95, 151, 222, 243, 261],\n",
       "   [2, 1, 70, 112, 165, 233, 239, 261],\n",
       "   [2, 0, 31, 99, 147, 231, 0, 244],\n",
       "   [2, 209, 25, 91, 171, 225, 242, 244],\n",
       "   [2, 190, 20, 90, 124, 234, 238, 261],\n",
       "   [3, 206, 33, 93, 135, 230, 243, 261],\n",
       "   [2, 217, 17, 111, 124, 234, 242, 244],\n",
       "   [2, 191, 37, 118, 158, 223, 243, 0],\n",
       "   [3, 188, 41, 103, 181, 225, 243, 261],\n",
       "   [3, 205, 12, 89, 180, 229, 238, 261],\n",
       "   [2, 199, 39, 90, 185, 225, 238, 244],\n",
       "   [2, 198, 47, 104, 157, 226, 0, 244],\n",
       "   [3, 192, 8, 109, 186, 223, 241, 261],\n",
       "   [3, 188, 56, 106, 164, 227, 240, 261],\n",
       "   [2, 217, 11, 116, 163, 0, 243, 0],\n",
       "   [2, 194, 29, 107, 123, 227, 239, 244],\n",
       "   [3, 196, 61, 96, 176, 222, 239, 261],\n",
       "   [3, 219, 75, 91, 147, 234, 241, 261],\n",
       "   [2, 207, 37, 118, 155, 228, 238, 244],\n",
       "   [3, 190, 62, 113, 163, 220, 240, 261],\n",
       "   [3, 192, 42, 108, 152, 223, 238, 261],\n",
       "   [2, 196, 38, 102, 137, 224, 0, 0],\n",
       "   [2, 211, 78, 91, 128, 228, 240, 261],\n",
       "   [3, 218, 77, 89, 155, 222, 243, 261],\n",
       "   [2, 215, 75, 107, 139, 231, 242, 261],\n",
       "   [2, 209, 27, 111, 152, 224, 238, 261],\n",
       "   [2, 193, 43, 116, 168, 234, 0, 261],\n",
       "   [2, 207, 70, 116, 156, 224, 0, 244],\n",
       "   [3, 206, 41, 92, 186, 229, 238, 261],\n",
       "   [3, 198, 41, 93, 147, 234, 239, 261],\n",
       "   [2, 192, 66, 114, 167, 228, 241, 261],\n",
       "   [3, 188, 52, 109, 130, 222, 240, 261],\n",
       "   [2, 209, 25, 107, 128, 234, 242, 244],\n",
       "   [2, 211, 29, 113, 147, 232, 0, 261],\n",
       "   [2, 213, 22, 105, 139, 222, 242, 261],\n",
       "   [3, 197, 62, 94, 180, 224, 238, 261],\n",
       "   [2, 188, 69, 111, 146, 222, 243, 244],\n",
       "   [2, 206, 67, 96, 131, 228, 242, 244],\n",
       "   [2, 192, 47, 98, 141, 221, 0, 244],\n",
       "   [3, 217, 55, 104, 171, 222, 240, 261],\n",
       "   [3, 206, 42, 108, 172, 225, 240, 261],\n",
       "   [2, 212, 49, 111, 172, 228, 240, 244],\n",
       "   [2, 209, 71, 110, 144, 227, 242, 261],\n",
       "   [3, 213, 78, 102, 142, 221, 239, 261],\n",
       "   [2, 194, 9, 105, 171, 0, 242, 0],\n",
       "   [2, 199, 13, 91, 131, 231, 241, 261],\n",
       "   [2, 210, 30, 117, 166, 222, 0, 0],\n",
       "   [2, 202, 41, 118, 162, 228, 0, 261],\n",
       "   [3, 195, 31, 111, 175, 223, 238, 261],\n",
       "   [2, 203, 59, 96, 136, 225, 243, 261],\n",
       "   [3, 201, 78, 111, 141, 226, 243, 261],\n",
       "   [2, 0, 48, 108, 123, 220, 243, 261],\n",
       "   [3, 187, 83, 99, 178, 222, 241, 261],\n",
       "   [2, 192, 37, 103, 130, 225, 243, 0],\n",
       "   [3, 197, 31, 110, 162, 220, 238, 261],\n",
       "   [2, 190, 40, 92, 140, 234, 0, 0],\n",
       "   [3, 213, 63, 95, 144, 222, 241, 261],\n",
       "   [2, 194, 81, 109, 132, 224, 238, 261],\n",
       "   [2, 209, 55, 93, 144, 0, 242, 244],\n",
       "   [3, 212, 32, 119, 169, 221, 241, 261],\n",
       "   [3, 201, 24, 118, 168, 234, 243, 261],\n",
       "   [2, 210, 31, 90, 178, 232, 242, 244],\n",
       "   [3, 218, 47, 97, 149, 220, 239, 261],\n",
       "   [2, 214, 61, 93, 127, 224, 240, 261],\n",
       "   [2, 198, 43, 90, 149, 0, 238, 0],\n",
       "   [3, 209, 64, 108, 129, 232, 242, 261],\n",
       "   [2, 200, 58, 94, 153, 226, 238, 261],\n",
       "   [2, 187, 13, 107, 133, 0, 243, 0],\n",
       "   [2, 197, 78, 119, 186, 0, 0, 244],\n",
       "   [2, 201, 13, 110, 179, 227, 240, 0],\n",
       "   [2, 197, 43, 102, 129, 225, 240, 261],\n",
       "   [2, 204, 8, 90, 182, 222, 241, 261],\n",
       "   [3, 218, 28, 104, 176, 223, 239, 261],\n",
       "   [2, 209, 31, 111, 168, 231, 238, 261],\n",
       "   [2, 195, 35, 99, 153, 224, 238, 244],\n",
       "   [2, 194, 24, 109, 152, 230, 243, 0],\n",
       "   [3, 216, 29, 94, 174, 230, 242, 261],\n",
       "   [2, 205, 32, 114, 152, 224, 0, 244],\n",
       "   [2, 190, 20, 119, 172, 229, 242, 0],\n",
       "   [2, 192, 38, 108, 186, 226, 241, 0],\n",
       "   [3, 206, 53, 114, 169, 228, 239, 261],\n",
       "   [2, 198, 6, 115, 172, 231, 243, 261],\n",
       "   [3, 198, 29, 92, 172, 226, 241, 261],\n",
       "   [3, 207, 35, 97, 157, 226, 240, 261],\n",
       "   [2, 204, 28, 95, 133, 226, 239, 261],\n",
       "   [2, 190, 29, 91, 183, 225, 243, 261],\n",
       "   [2, 206, 42, 91, 135, 224, 238, 244],\n",
       "   [3, 1, 61, 105, 138, 228, 239, 261],\n",
       "   [2, 209, 80, 102, 149, 222, 0, 244],\n",
       "   [2, 190, 65, 106, 139, 222, 242, 244],\n",
       "   [3, 207, 60, 95, 170, 226, 240, 261],\n",
       "   [3, 188, 43, 100, 129, 233, 240, 261],\n",
       "   [2, 196, 50, 115, 125, 226, 243, 261],\n",
       "   [2, 214, 31, 93, 135, 225, 239, 0],\n",
       "   [2, 203, 36, 92, 153, 229, 238, 0],\n",
       "   [2, 209, 43, 114, 146, 223, 0, 244],\n",
       "   [2, 195, 6, 108, 161, 223, 241, 0],\n",
       "   [2, 196, 33, 111, 144, 0, 243, 244],\n",
       "   [2, 200, 20, 93, 175, 227, 238, 244],\n",
       "   [2, 217, 68, 107, 137, 221, 241, 0],\n",
       "   [2, 206, 55, 98, 165, 222, 240, 244],\n",
       "   [3, 194, 16, 102, 171, 221, 243, 261],\n",
       "   [2, 205, 69, 96, 176, 223, 240, 0],\n",
       "   [3, 189, 30, 89, 159, 224, 243, 261],\n",
       "   [2, 194, 40, 101, 146, 222, 0, 244],\n",
       "   [3, 214, 11, 111, 160, 224, 241, 261],\n",
       "   [2, 211, 33, 115, 175, 233, 239, 244],\n",
       "   [2, 195, 28, 95, 149, 233, 239, 261],\n",
       "   [2, 201, 17, 95, 123, 0, 243, 261],\n",
       "   [3, 200, 24, 118, 164, 221, 239, 261],\n",
       "   [3, 219, 59, 103, 125, 223, 241, 261],\n",
       "   [2, 195, 70, 90, 186, 223, 238, 244],\n",
       "   [2, 215, 44, 108, 149, 221, 242, 0],\n",
       "   [2, 218, 53, 105, 167, 221, 242, 244],\n",
       "   [2, 194, 33, 109, 132, 226, 0, 261],\n",
       "   [2, 192, 37, 115, 143, 227, 0, 261],\n",
       "   [2, 187, 39, 114, 135, 221, 0, 0],\n",
       "   [2, 205, 10, 92, 158, 225, 238, 0],\n",
       "   [3, 191, 37, 109, 142, 223, 242, 261],\n",
       "   [2, 206, 39, 100, 149, 225, 0, 261],\n",
       "   [2, 196, 43, 111, 185, 227, 242, 244],\n",
       "   [3, 205, 63, 115, 163, 222, 239, 261],\n",
       "   [2, 215, 50, 98, 148, 230, 240, 244],\n",
       "   [2, 195, 19, 91, 174, 224, 241, 244],\n",
       "   [2, 190, 51, 105, 180, 223, 241, 0],\n",
       "   [2, 194, 29, 104, 172, 230, 242, 261],\n",
       "   [3, 219, 30, 104, 171, 231, 243, 261],\n",
       "   [2, 218, 31, 102, 159, 231, 0, 244],\n",
       "   [2, 199, 30, 91, 144, 230, 243, 0],\n",
       "   [2, 205, 49, 98, 126, 229, 238, 261],\n",
       "   [2, 209, 58, 116, 150, 228, 240, 0],\n",
       "   [2, 206, 35, 94, 167, 227, 243, 244],\n",
       "   [3, 207, 10, 91, 128, 230, 241, 261],\n",
       "   [3, 201, 12, 108, 167, 233, 243, 261],\n",
       "   [2, 209, 87, 114, 164, 225, 238, 261],\n",
       "   [2, 206, 42, 106, 169, 233, 241, 244],\n",
       "   [2, 218, 77, 98, 178, 222, 243, 261],\n",
       "   [2, 218, 70, 98, 141, 226, 243, 244],\n",
       "   [2, 215, 77, 102, 186, 231, 241, 244],\n",
       "   [3, 190, 7, 89, 160, 222, 243, 261],\n",
       "   [2, 204, 32, 106, 142, 221, 0, 261]]],\n",
       " [[[2, 204, 26, 92, 132, 231, 242, 244],\n",
       "   [2, 201, 43, 90, 173, 224, 243, 261],\n",
       "   [2, 217, 11, 117, 175, 229, 243, 261],\n",
       "   [2, 193, 59, 115, 126, 225, 243, 244],\n",
       "   [2, 191, 16, 109, 139, 228, 238, 261],\n",
       "   [2, 210, 44, 91, 163, 232, 242, 0],\n",
       "   [2, 219, 38, 99, 157, 225, 241, 261],\n",
       "   [2, 191, 17, 100, 137, 230, 239, 261],\n",
       "   [2, 215, 7, 97, 158, 234, 240, 0],\n",
       "   [2, 206, 9, 115, 127, 233, 0, 0],\n",
       "   [2, 199, 29, 108, 155, 222, 239, 0],\n",
       "   [2, 216, 50, 96, 174, 234, 239, 0],\n",
       "   [2, 218, 12, 101, 149, 233, 243, 0],\n",
       "   [2, 211, 65, 98, 153, 230, 0, 0],\n",
       "   [3, 211, 63, 92, 150, 229, 241, 261],\n",
       "   [3, 216, 0, 112, 163, 230, 239, 261],\n",
       "   [2, 193, 34, 101, 127, 222, 242, 244],\n",
       "   [2, 216, 59, 101, 172, 231, 242, 0],\n",
       "   [2, 208, 16, 97, 180, 225, 0, 0],\n",
       "   [2, 200, 57, 101, 185, 227, 240, 244],\n",
       "   [2, 203, 15, 111, 175, 228, 243, 244],\n",
       "   [3, 197, 31, 119, 160, 231, 240, 261],\n",
       "   [2, 187, 27, 91, 128, 231, 243, 261],\n",
       "   [2, 203, 8, 90, 154, 226, 239, 0],\n",
       "   [2, 194, 48, 108, 164, 229, 239, 261],\n",
       "   [3, 190, 26, 111, 177, 232, 241, 261],\n",
       "   [3, 192, 6, 104, 146, 222, 240, 261],\n",
       "   [3, 192, 78, 100, 149, 232, 238, 261],\n",
       "   [3, 192, 9, 111, 144, 221, 241, 261],\n",
       "   [3, 191, 47, 97, 179, 232, 242, 261],\n",
       "   [3, 202, 15, 101, 152, 226, 239, 261],\n",
       "   [2, 1, 58, 96, 166, 229, 243, 261],\n",
       "   [2, 211, 31, 111, 148, 231, 239, 0],\n",
       "   [3, 206, 61, 104, 173, 226, 243, 261],\n",
       "   [3, 212, 81, 90, 168, 231, 239, 261],\n",
       "   [2, 188, 71, 105, 174, 234, 243, 261],\n",
       "   [3, 212, 67, 96, 163, 225, 238, 261],\n",
       "   [2, 201, 35, 114, 171, 224, 243, 244],\n",
       "   [2, 199, 27, 104, 171, 223, 0, 244],\n",
       "   [2, 208, 18, 90, 186, 223, 240, 261],\n",
       "   [3, 215, 11, 90, 162, 223, 243, 261],\n",
       "   [3, 198, 18, 101, 164, 222, 242, 261],\n",
       "   [3, 219, 32, 93, 127, 228, 243, 261],\n",
       "   [3, 204, 35, 108, 136, 227, 238, 261],\n",
       "   [3, 201, 58, 93, 168, 234, 239, 261],\n",
       "   [2, 189, 82, 92, 178, 223, 243, 261],\n",
       "   [2, 206, 61, 115, 163, 220, 241, 0],\n",
       "   [3, 187, 0, 96, 136, 228, 242, 261],\n",
       "   [2, 214, 56, 110, 139, 224, 0, 261],\n",
       "   [2, 200, 29, 92, 138, 226, 242, 261],\n",
       "   [3, 199, 31, 89, 139, 225, 241, 261],\n",
       "   [2, 198, 65, 90, 179, 223, 243, 261],\n",
       "   [2, 188, 12, 110, 151, 223, 240, 261],\n",
       "   [3, 201, 71, 99, 162, 233, 243, 261],\n",
       "   [3, 216, 79, 112, 177, 223, 238, 261],\n",
       "   [2, 192, 66, 96, 126, 226, 243, 0],\n",
       "   [2, 191, 51, 98, 137, 234, 242, 0],\n",
       "   [2, 203, 80, 94, 174, 221, 240, 0],\n",
       "   [2, 202, 15, 90, 170, 232, 243, 244],\n",
       "   [2, 201, 72, 91, 131, 229, 239, 244],\n",
       "   [2, 201, 58, 103, 130, 233, 0, 261],\n",
       "   [3, 189, 30, 96, 127, 233, 240, 261],\n",
       "   [2, 199, 46, 95, 151, 234, 238, 244],\n",
       "   [3, 1, 12, 96, 125, 234, 238, 261],\n",
       "   [2, 188, 72, 110, 175, 231, 240, 244],\n",
       "   [2, 209, 35, 114, 133, 225, 242, 261],\n",
       "   [2, 206, 40, 108, 182, 222, 238, 261],\n",
       "   [3, 206, 83, 117, 140, 220, 242, 261],\n",
       "   [2, 207, 73, 102, 168, 221, 239, 0],\n",
       "   [2, 209, 57, 103, 141, 221, 243, 244],\n",
       "   [2, 188, 36, 101, 143, 0, 242, 261],\n",
       "   [2, 190, 13, 95, 135, 225, 0, 0],\n",
       "   [3, 205, 15, 92, 183, 225, 243, 261],\n",
       "   [3, 212, 41, 95, 157, 230, 240, 261],\n",
       "   [2, 206, 25, 95, 135, 226, 242, 261],\n",
       "   [3, 199, 23, 91, 168, 230, 241, 261],\n",
       "   [2, 212, 52, 94, 183, 220, 239, 261],\n",
       "   [3, 214, 38, 110, 126, 226, 243, 261],\n",
       "   [2, 188, 77, 98, 185, 0, 239, 261],\n",
       "   [2, 192, 60, 103, 174, 0, 239, 261],\n",
       "   [2, 198, 70, 99, 170, 231, 0, 0],\n",
       "   [3, 208, 0, 0, 179, 223, 241, 261],\n",
       "   [2, 214, 12, 110, 145, 233, 241, 0],\n",
       "   [2, 209, 72, 97, 165, 233, 243, 0],\n",
       "   [3, 210, 23, 108, 152, 222, 243, 261],\n",
       "   [2, 196, 30, 96, 145, 230, 238, 261],\n",
       "   [2, 188, 23, 100, 182, 229, 238, 0],\n",
       "   [2, 203, 33, 115, 142, 233, 240, 261],\n",
       "   [2, 192, 42, 95, 184, 224, 243, 244],\n",
       "   [2, 207, 65, 93, 129, 225, 243, 244],\n",
       "   [2, 200, 56, 104, 137, 222, 239, 244],\n",
       "   [3, 187, 4, 89, 136, 229, 243, 261],\n",
       "   [2, 205, 28, 109, 155, 230, 243, 261],\n",
       "   [3, 195, 24, 100, 186, 229, 241, 261],\n",
       "   [2, 205, 87, 114, 129, 231, 0, 261],\n",
       "   [2, 193, 23, 93, 149, 231, 238, 261],\n",
       "   [2, 193, 77, 103, 148, 230, 239, 261],\n",
       "   [2, 194, 49, 104, 167, 225, 240, 244],\n",
       "   [3, 216, 67, 0, 124, 221, 238, 261],\n",
       "   [2, 196, 30, 109, 161, 0, 0, 0],\n",
       "   [2, 206, 33, 101, 150, 226, 238, 0],\n",
       "   [2, 200, 10, 111, 184, 225, 242, 0],\n",
       "   [3, 199, 53, 92, 165, 234, 241, 261],\n",
       "   [2, 214, 64, 106, 182, 221, 0, 244],\n",
       "   [2, 218, 36, 100, 173, 222, 240, 244],\n",
       "   [2, 195, 84, 100, 144, 221, 0, 0],\n",
       "   [2, 204, 27, 116, 157, 220, 240, 0],\n",
       "   [3, 197, 37, 94, 150, 234, 238, 261],\n",
       "   [3, 204, 7, 116, 136, 231, 242, 261],\n",
       "   [2, 218, 43, 114, 157, 229, 240, 0],\n",
       "   [3, 211, 67, 89, 164, 223, 243, 261],\n",
       "   [2, 194, 27, 116, 138, 227, 239, 0],\n",
       "   [2, 207, 74, 107, 183, 230, 0, 0],\n",
       "   [3, 207, 32, 92, 151, 226, 243, 261],\n",
       "   [2, 219, 6, 114, 161, 229, 239, 261],\n",
       "   [2, 198, 47, 111, 151, 232, 238, 244],\n",
       "   [2, 210, 65, 101, 142, 234, 239, 261],\n",
       "   [3, 201, 37, 106, 174, 228, 243, 261],\n",
       "   [2, 214, 48, 107, 185, 232, 0, 261],\n",
       "   [2, 217, 77, 100, 154, 226, 0, 0],\n",
       "   [2, 218, 45, 118, 170, 223, 241, 261],\n",
       "   [2, 203, 59, 92, 162, 229, 239, 244],\n",
       "   [2, 201, 27, 109, 177, 225, 0, 261],\n",
       "   [2, 213, 38, 90, 136, 233, 243, 244],\n",
       "   [2, 205, 42, 113, 124, 229, 0, 0],\n",
       "   [3, 190, 20, 90, 160, 230, 243, 261],\n",
       "   [2, 193, 24, 114, 133, 221, 243, 0],\n",
       "   [2, 216, 50, 108, 164, 220, 0, 261],\n",
       "   [2, 197, 16, 119, 123, 222, 240, 0],\n",
       "   [2, 203, 32, 119, 140, 229, 238, 244],\n",
       "   [3, 215, 19, 117, 172, 227, 238, 261],\n",
       "   [3, 207, 8, 96, 135, 225, 241, 261],\n",
       "   [2, 195, 34, 105, 161, 221, 243, 0],\n",
       "   [2, 207, 29, 96, 140, 225, 243, 261],\n",
       "   [2, 207, 42, 117, 174, 225, 242, 261],\n",
       "   [2, 198, 25, 117, 139, 222, 242, 244],\n",
       "   [2, 191, 29, 109, 126, 224, 0, 0],\n",
       "   [2, 199, 56, 113, 178, 232, 239, 0],\n",
       "   [2, 211, 62, 90, 123, 0, 242, 244],\n",
       "   [3, 219, 9, 90, 136, 221, 241, 261],\n",
       "   [3, 194, 7, 0, 175, 223, 238, 261],\n",
       "   [2, 194, 37, 119, 160, 225, 0, 244],\n",
       "   [2, 217, 28, 107, 172, 220, 242, 0],\n",
       "   [2, 197, 33, 111, 130, 228, 238, 261],\n",
       "   [2, 201, 33, 119, 158, 224, 238, 0],\n",
       "   [2, 194, 82, 109, 148, 224, 241, 244],\n",
       "   [2, 218, 45, 111, 139, 229, 243, 244],\n",
       "   [3, 206, 73, 93, 134, 234, 241, 261],\n",
       "   [2, 199, 77, 91, 135, 0, 238, 244],\n",
       "   [2, 191, 74, 92, 139, 223, 241, 261],\n",
       "   [2, 189, 71, 97, 160, 233, 243, 244],\n",
       "   [2, 207, 69, 113, 155, 222, 242, 244],\n",
       "   [3, 210, 45, 94, 132, 222, 241, 261],\n",
       "   [2, 213, 72, 93, 145, 232, 243, 261],\n",
       "   [2, 190, 33, 99, 127, 231, 238, 261],\n",
       "   [2, 195, 62, 112, 167, 223, 240, 0],\n",
       "   [3, 203, 15, 0, 153, 226, 243, 261],\n",
       "   [2, 218, 37, 90, 127, 226, 243, 261],\n",
       "   [2, 209, 7, 94, 176, 234, 243, 244],\n",
       "   [2, 195, 73, 100, 139, 234, 241, 0],\n",
       "   [2, 194, 9, 101, 176, 227, 0, 261],\n",
       "   [2, 200, 87, 108, 156, 234, 242, 244],\n",
       "   [3, 202, 54, 115, 174, 226, 243, 261],\n",
       "   [3, 219, 35, 112, 181, 229, 243, 261],\n",
       "   [2, 194, 51, 92, 132, 231, 0, 0],\n",
       "   [2, 215, 11, 90, 171, 225, 238, 0],\n",
       "   [2, 194, 40, 98, 165, 223, 243, 244],\n",
       "   [2, 203, 39, 111, 147, 223, 0, 244],\n",
       "   [2, 192, 51, 90, 182, 229, 243, 0],\n",
       "   [2, 194, 28, 116, 158, 0, 243, 261],\n",
       "   [2, 200, 63, 110, 149, 222, 242, 0],\n",
       "   [2, 199, 64, 113, 132, 229, 239, 261],\n",
       "   [2, 209, 59, 111, 150, 229, 242, 261],\n",
       "   [2, 204, 17, 111, 166, 232, 243, 0],\n",
       "   [2, 210, 15, 92, 139, 223, 0, 261],\n",
       "   [2, 198, 71, 93, 156, 223, 241, 244],\n",
       "   [3, 197, 72, 91, 155, 223, 243, 261],\n",
       "   [2, 196, 53, 94, 139, 224, 240, 244],\n",
       "   [2, 0, 24, 91, 159, 220, 240, 261],\n",
       "   [3, 209, 33, 93, 141, 226, 243, 261],\n",
       "   [3, 200, 32, 90, 172, 223, 243, 261],\n",
       "   [2, 209, 11, 111, 130, 223, 243, 261],\n",
       "   [3, 195, 9, 100, 156, 225, 239, 261],\n",
       "   [2, 191, 88, 106, 164, 229, 238, 244],\n",
       "   [2, 205, 63, 102, 170, 234, 242, 261],\n",
       "   [3, 191, 85, 95, 143, 231, 242, 261],\n",
       "   [2, 194, 39, 108, 150, 224, 0, 261],\n",
       "   [2, 206, 29, 118, 171, 222, 238, 0],\n",
       "   [2, 203, 28, 100, 139, 227, 0, 0],\n",
       "   [2, 198, 43, 112, 185, 229, 241, 261],\n",
       "   [3, 199, 12, 98, 171, 223, 241, 261],\n",
       "   [2, 200, 13, 104, 130, 223, 0, 261],\n",
       "   [3, 206, 45, 94, 186, 232, 238, 261],\n",
       "   [2, 214, 9, 96, 167, 232, 243, 244],\n",
       "   [2, 205, 40, 115, 151, 231, 0, 261],\n",
       "   [3, 202, 9, 112, 185, 229, 240, 261],\n",
       "   [2, 187, 79, 96, 123, 220, 0, 0],\n",
       "   [2, 202, 10, 114, 179, 221, 0, 261],\n",
       "   [2, 204, 35, 104, 165, 220, 0, 0],\n",
       "   [3, 189, 60, 106, 123, 222, 239, 261],\n",
       "   [2, 206, 10, 101, 155, 233, 0, 244]]],\n",
       " [[[2, 205, 33, 92, 157, 224, 238, 0],\n",
       "   [2, 192, 67, 92, 166, 224, 243, 261],\n",
       "   [2, 197, 52, 91, 151, 222, 243, 261],\n",
       "   [2, 214, 28, 113, 130, 220, 242, 244],\n",
       "   [2, 208, 13, 93, 178, 0, 239, 244],\n",
       "   [3, 187, 47, 97, 133, 230, 238, 261],\n",
       "   [2, 215, 85, 105, 162, 220, 0, 0],\n",
       "   [2, 191, 62, 99, 129, 232, 241, 261],\n",
       "   [2, 212, 86, 119, 148, 230, 0, 0],\n",
       "   [2, 200, 27, 98, 143, 220, 241, 0],\n",
       "   [3, 218, 67, 111, 129, 227, 239, 261],\n",
       "   [3, 198, 47, 105, 173, 227, 239, 261],\n",
       "   [2, 212, 85, 112, 174, 233, 240, 0],\n",
       "   [3, 201, 87, 108, 127, 232, 238, 261],\n",
       "   [3, 190, 75, 89, 179, 230, 238, 261],\n",
       "   [2, 200, 61, 93, 156, 233, 0, 244],\n",
       "   [3, 198, 51, 115, 136, 222, 241, 261],\n",
       "   [2, 209, 8, 115, 129, 220, 240, 0],\n",
       "   [3, 1, 70, 108, 156, 232, 243, 261],\n",
       "   [3, 217, 66, 106, 142, 226, 243, 261],\n",
       "   [2, 208, 56, 105, 146, 230, 242, 244],\n",
       "   [3, 201, 72, 105, 132, 221, 240, 261],\n",
       "   [3, 207, 31, 91, 124, 231, 241, 261],\n",
       "   [2, 190, 47, 96, 181, 0, 0, 244],\n",
       "   [2, 1, 28, 115, 183, 226, 243, 261],\n",
       "   [3, 193, 15, 96, 172, 229, 243, 261],\n",
       "   [2, 190, 29, 117, 180, 227, 242, 0],\n",
       "   [3, 209, 84, 106, 123, 226, 242, 261],\n",
       "   [3, 197, 18, 113, 150, 231, 241, 261],\n",
       "   [3, 219, 80, 92, 178, 229, 242, 261],\n",
       "   [3, 213, 22, 96, 141, 222, 242, 261],\n",
       "   [3, 197, 35, 97, 166, 230, 239, 261],\n",
       "   [2, 210, 10, 100, 168, 234, 0, 261],\n",
       "   [2, 205, 61, 101, 125, 226, 238, 261],\n",
       "   [2, 188, 34, 106, 157, 227, 241, 244],\n",
       "   [2, 215, 29, 107, 142, 221, 238, 0],\n",
       "   [2, 218, 30, 102, 156, 228, 243, 244],\n",
       "   [3, 211, 82, 105, 153, 231, 238, 261],\n",
       "   [3, 199, 58, 91, 133, 230, 241, 261],\n",
       "   [3, 202, 54, 108, 139, 227, 240, 261],\n",
       "   [3, 190, 43, 0, 160, 227, 241, 261],\n",
       "   [2, 193, 8, 98, 179, 220, 242, 244],\n",
       "   [3, 211, 21, 108, 179, 232, 238, 261],\n",
       "   [2, 204, 31, 95, 124, 228, 240, 244],\n",
       "   [2, 193, 67, 90, 124, 222, 243, 261],\n",
       "   [3, 211, 76, 0, 122, 234, 240, 261],\n",
       "   [2, 197, 59, 99, 183, 224, 242, 261],\n",
       "   [3, 214, 88, 98, 184, 221, 240, 261],\n",
       "   [2, 195, 35, 98, 165, 232, 242, 244],\n",
       "   [2, 188, 75, 96, 138, 234, 240, 244],\n",
       "   [2, 194, 55, 107, 170, 222, 239, 261],\n",
       "   [3, 210, 80, 119, 126, 233, 238, 261],\n",
       "   [2, 187, 62, 101, 140, 230, 242, 261],\n",
       "   [2, 198, 28, 107, 181, 220, 240, 261],\n",
       "   [2, 205, 6, 105, 125, 222, 240, 244],\n",
       "   [2, 197, 39, 94, 130, 229, 241, 0],\n",
       "   [3, 197, 81, 118, 141, 232, 238, 261],\n",
       "   [3, 206, 64, 113, 129, 229, 242, 261],\n",
       "   [3, 216, 19, 97, 166, 221, 241, 261],\n",
       "   [2, 215, 60, 113, 127, 223, 239, 261],\n",
       "   [2, 210, 74, 97, 175, 223, 239, 261],\n",
       "   [3, 219, 0, 101, 134, 232, 241, 261],\n",
       "   [3, 187, 11, 113, 177, 231, 242, 261],\n",
       "   [3, 205, 87, 92, 146, 221, 238, 261],\n",
       "   [2, 0, 61, 90, 133, 222, 242, 261],\n",
       "   [2, 200, 45, 93, 181, 224, 238, 0],\n",
       "   [2, 214, 74, 108, 158, 225, 241, 261],\n",
       "   [2, 213, 16, 100, 160, 226, 240, 261],\n",
       "   [2, 215, 60, 99, 145, 228, 240, 244],\n",
       "   [3, 195, 30, 114, 150, 228, 238, 261],\n",
       "   [3, 188, 57, 97, 172, 233, 239, 261],\n",
       "   [3, 213, 65, 104, 182, 225, 241, 261],\n",
       "   [2, 214, 38, 100, 155, 223, 240, 261],\n",
       "   [2, 209, 85, 110, 168, 232, 241, 0],\n",
       "   [2, 199, 26, 91, 152, 226, 239, 261],\n",
       "   [2, 201, 66, 108, 178, 226, 242, 0],\n",
       "   [3, 196, 12, 89, 182, 234, 238, 261],\n",
       "   [3, 209, 27, 93, 172, 224, 243, 261],\n",
       "   [2, 190, 84, 116, 151, 228, 239, 244],\n",
       "   [3, 204, 26, 0, 133, 226, 243, 261],\n",
       "   [3, 214, 61, 118, 179, 220, 240, 261],\n",
       "   [2, 193, 49, 107, 158, 233, 238, 244],\n",
       "   [2, 1, 56, 117, 176, 225, 242, 0],\n",
       "   [3, 194, 87, 99, 180, 227, 240, 261],\n",
       "   [3, 204, 88, 99, 159, 224, 239, 261],\n",
       "   [3, 215, 14, 108, 130, 227, 242, 261],\n",
       "   [2, 196, 72, 107, 176, 228, 241, 261],\n",
       "   [2, 204, 82, 112, 128, 234, 241, 261],\n",
       "   [2, 208, 53, 115, 143, 232, 240, 0],\n",
       "   [3, 196, 63, 94, 176, 231, 239, 261],\n",
       "   [2, 206, 79, 91, 155, 233, 241, 261],\n",
       "   [2, 212, 85, 100, 143, 231, 240, 0],\n",
       "   [3, 198, 30, 117, 176, 220, 238, 261],\n",
       "   [2, 197, 38, 91, 178, 222, 242, 244],\n",
       "   [2, 212, 69, 110, 128, 230, 238, 261],\n",
       "   [3, 215, 56, 93, 157, 228, 241, 261],\n",
       "   [3, 1, 15, 101, 178, 227, 238, 261],\n",
       "   [2, 195, 73, 105, 151, 234, 0, 261],\n",
       "   [3, 218, 43, 117, 164, 231, 240, 261],\n",
       "   [2, 196, 29, 101, 124, 231, 242, 261],\n",
       "   [2, 205, 72, 91, 124, 221, 241, 0],\n",
       "   [2, 190, 47, 96, 148, 224, 239, 261],\n",
       "   [3, 215, 60, 102, 172, 222, 240, 261],\n",
       "   [2, 192, 18, 113, 159, 234, 239, 244],\n",
       "   [2, 202, 49, 119, 128, 220, 243, 261],\n",
       "   [2, 207, 24, 90, 136, 232, 238, 244],\n",
       "   [2, 212, 26, 97, 143, 230, 242, 261],\n",
       "   [2, 207, 7, 119, 184, 226, 241, 0],\n",
       "   [2, 190, 63, 97, 143, 233, 240, 261],\n",
       "   [2, 200, 69, 113, 156, 230, 242, 261],\n",
       "   [3, 188, 87, 96, 142, 231, 243, 261],\n",
       "   [3, 195, 22, 116, 134, 223, 242, 261],\n",
       "   [2, 204, 69, 114, 171, 234, 238, 0],\n",
       "   [2, 206, 84, 107, 145, 221, 242, 261],\n",
       "   [3, 195, 78, 113, 149, 232, 240, 261],\n",
       "   [3, 218, 39, 103, 131, 229, 242, 261],\n",
       "   [3, 190, 37, 93, 179, 220, 240, 261],\n",
       "   [2, 202, 70, 117, 163, 0, 241, 0],\n",
       "   [3, 208, 56, 89, 0, 224, 243, 261],\n",
       "   [2, 209, 21, 99, 157, 223, 0, 261],\n",
       "   [2, 203, 81, 94, 139, 0, 0, 244],\n",
       "   [3, 1, 73, 94, 132, 228, 238, 261],\n",
       "   [3, 199, 13, 118, 135, 227, 241, 261],\n",
       "   [2, 200, 60, 111, 139, 220, 240, 261],\n",
       "   [2, 213, 36, 100, 126, 232, 243, 244],\n",
       "   [2, 192, 64, 117, 173, 231, 240, 244],\n",
       "   [2, 194, 21, 95, 141, 229, 242, 244],\n",
       "   [2, 1, 7, 117, 145, 224, 0, 0],\n",
       "   [2, 216, 76, 106, 174, 224, 0, 261],\n",
       "   [2, 194, 59, 115, 140, 220, 243, 244],\n",
       "   [2, 210, 62, 100, 167, 227, 239, 0],\n",
       "   [2, 189, 11, 94, 173, 230, 238, 244],\n",
       "   [3, 217, 31, 111, 160, 232, 243, 261],\n",
       "   [2, 191, 33, 96, 163, 230, 243, 0],\n",
       "   [3, 188, 64, 95, 146, 228, 242, 261],\n",
       "   [2, 196, 8, 98, 170, 231, 242, 261],\n",
       "   [2, 200, 75, 103, 135, 222, 238, 244],\n",
       "   [3, 192, 58, 90, 128, 230, 238, 261],\n",
       "   [3, 219, 53, 107, 156, 232, 238, 261],\n",
       "   [2, 215, 53, 96, 154, 229, 240, 0],\n",
       "   [2, 188, 66, 95, 180, 233, 0, 261],\n",
       "   [2, 214, 44, 98, 125, 232, 240, 261],\n",
       "   [3, 197, 78, 117, 170, 234, 238, 261],\n",
       "   [2, 216, 48, 96, 182, 226, 243, 261],\n",
       "   [3, 193, 59, 108, 148, 232, 240, 261],\n",
       "   [2, 192, 14, 93, 184, 225, 243, 261],\n",
       "   [2, 187, 35, 116, 131, 228, 0, 261],\n",
       "   [2, 200, 26, 93, 144, 0, 0, 244],\n",
       "   [2, 0, 15, 90, 149, 230, 240, 0],\n",
       "   [2, 190, 67, 112, 179, 231, 239, 244],\n",
       "   [2, 219, 43, 108, 158, 228, 239, 261],\n",
       "   [2, 189, 81, 96, 173, 225, 240, 261],\n",
       "   [2, 1, 34, 90, 167, 225, 242, 244],\n",
       "   [2, 215, 30, 107, 183, 220, 238, 261],\n",
       "   [2, 211, 55, 90, 150, 225, 243, 261],\n",
       "   [2, 192, 78, 109, 157, 227, 243, 244],\n",
       "   [3, 201, 87, 98, 147, 223, 243, 261],\n",
       "   [3, 207, 38, 118, 138, 221, 243, 261],\n",
       "   [3, 190, 58, 101, 182, 230, 239, 261],\n",
       "   [2, 1, 79, 95, 144, 234, 241, 0],\n",
       "   [2, 208, 38, 93, 175, 225, 242, 261],\n",
       "   [2, 192, 55, 101, 144, 220, 239, 0],\n",
       "   [3, 200, 83, 116, 133, 232, 241, 261],\n",
       "   [2, 207, 56, 107, 166, 232, 240, 0],\n",
       "   [2, 188, 46, 111, 124, 227, 241, 244],\n",
       "   [3, 188, 78, 94, 183, 221, 238, 261],\n",
       "   [3, 207, 25, 95, 180, 223, 243, 261],\n",
       "   [3, 207, 39, 110, 169, 234, 243, 261],\n",
       "   [3, 198, 28, 91, 186, 223, 239, 261],\n",
       "   [2, 200, 30, 109, 143, 222, 243, 261],\n",
       "   [2, 199, 88, 95, 145, 234, 239, 261],\n",
       "   [2, 204, 64, 100, 129, 224, 238, 0],\n",
       "   [2, 187, 27, 116, 178, 225, 241, 244],\n",
       "   [2, 196, 88, 111, 141, 230, 240, 261],\n",
       "   [2, 218, 13, 101, 178, 231, 238, 0],\n",
       "   [2, 211, 27, 115, 142, 221, 240, 244],\n",
       "   [2, 209, 9, 117, 175, 229, 242, 261],\n",
       "   [2, 193, 26, 101, 147, 229, 243, 0],\n",
       "   [2, 213, 87, 114, 137, 224, 241, 244],\n",
       "   [2, 209, 37, 92, 177, 226, 243, 244],\n",
       "   [3, 211, 11, 102, 173, 223, 238, 261],\n",
       "   [3, 192, 65, 97, 126, 234, 242, 261],\n",
       "   [2, 217, 61, 108, 139, 229, 239, 0],\n",
       "   [2, 218, 72, 117, 153, 234, 238, 261],\n",
       "   [3, 194, 41, 106, 154, 220, 240, 261],\n",
       "   [2, 192, 43, 105, 139, 220, 243, 244],\n",
       "   [2, 196, 19, 102, 147, 233, 240, 0],\n",
       "   [2, 192, 39, 95, 186, 232, 239, 244],\n",
       "   [3, 190, 60, 94, 167, 220, 243, 261],\n",
       "   [2, 202, 59, 119, 170, 234, 239, 261],\n",
       "   [3, 207, 63, 118, 142, 231, 238, 261],\n",
       "   [2, 219, 87, 118, 184, 223, 0, 0],\n",
       "   [2, 204, 56, 110, 146, 231, 243, 0],\n",
       "   [2, 189, 6, 111, 124, 234, 243, 261],\n",
       "   [3, 210, 83, 119, 182, 228, 238, 261],\n",
       "   [2, 200, 52, 92, 129, 221, 241, 244],\n",
       "   [2, 218, 33, 108, 136, 225, 241, 244],\n",
       "   [2, 206, 88, 99, 141, 226, 242, 261],\n",
       "   [2, 195, 28, 114, 150, 231, 241, 0],\n",
       "   [2, 214, 23, 104, 150, 224, 238, 261],\n",
       "   [2, 211, 22, 102, 163, 220, 243, 261]]],\n",
       " [[[2, 214, 24, 100, 166, 229, 239, 261],\n",
       "   [2, 197, 68, 91, 132, 224, 243, 244],\n",
       "   [2, 197, 74, 94, 125, 225, 0, 0],\n",
       "   [2, 210, 82, 117, 136, 231, 241, 0],\n",
       "   [2, 192, 58, 118, 123, 224, 0, 261],\n",
       "   [2, 205, 63, 113, 153, 225, 239, 244],\n",
       "   [2, 199, 64, 96, 160, 223, 242, 0],\n",
       "   [2, 1, 75, 114, 168, 227, 240, 0],\n",
       "   [2, 212, 55, 92, 133, 228, 242, 261],\n",
       "   [3, 219, 25, 94, 150, 220, 239, 261],\n",
       "   [2, 204, 78, 114, 185, 234, 240, 244],\n",
       "   [2, 195, 47, 105, 160, 230, 241, 244],\n",
       "   [2, 218, 60, 108, 128, 228, 0, 0],\n",
       "   [2, 200, 40, 109, 170, 230, 0, 0],\n",
       "   [2, 201, 41, 118, 136, 232, 0, 0],\n",
       "   [2, 0, 81, 112, 127, 232, 0, 261],\n",
       "   [2, 213, 35, 119, 126, 227, 0, 0],\n",
       "   [2, 213, 79, 98, 174, 231, 243, 261],\n",
       "   [2, 190, 73, 104, 161, 234, 243, 244],\n",
       "   [2, 214, 82, 118, 184, 231, 238, 261],\n",
       "   [3, 214, 32, 0, 178, 224, 243, 261],\n",
       "   [3, 199, 24, 115, 162, 230, 238, 261],\n",
       "   [2, 213, 84, 90, 131, 232, 240, 261],\n",
       "   [3, 202, 30, 119, 143, 232, 242, 261],\n",
       "   [2, 219, 42, 115, 156, 231, 238, 0],\n",
       "   [2, 197, 23, 107, 174, 234, 239, 244],\n",
       "   [2, 201, 41, 103, 139, 228, 0, 244],\n",
       "   [2, 207, 30, 116, 152, 222, 239, 261],\n",
       "   [2, 190, 27, 108, 146, 234, 239, 244],\n",
       "   [2, 198, 28, 97, 135, 224, 243, 0],\n",
       "   [2, 193, 16, 117, 141, 220, 0, 0],\n",
       "   [2, 208, 43, 115, 160, 232, 240, 0],\n",
       "   [2, 218, 22, 93, 140, 222, 238, 244],\n",
       "   [2, 207, 21, 96, 128, 227, 240, 244],\n",
       "   [2, 198, 84, 101, 173, 223, 238, 261],\n",
       "   [2, 207, 42, 114, 141, 228, 243, 244],\n",
       "   [2, 204, 53, 111, 167, 232, 0, 244],\n",
       "   [2, 210, 34, 116, 181, 224, 240, 244],\n",
       "   [2, 190, 57, 115, 181, 232, 238, 0],\n",
       "   [3, 201, 39, 116, 150, 220, 240, 261],\n",
       "   [2, 216, 41, 117, 169, 229, 239, 261],\n",
       "   [2, 214, 39, 116, 143, 232, 0, 261],\n",
       "   [2, 198, 42, 113, 157, 223, 0, 244],\n",
       "   [2, 205, 28, 111, 146, 220, 0, 244],\n",
       "   [3, 192, 68, 99, 174, 222, 243, 261],\n",
       "   [2, 200, 47, 103, 134, 233, 243, 261],\n",
       "   [2, 208, 42, 92, 159, 234, 240, 0],\n",
       "   [2, 191, 33, 118, 151, 224, 0, 261],\n",
       "   [2, 194, 81, 103, 149, 234, 0, 261],\n",
       "   [2, 212, 26, 119, 169, 230, 0, 244],\n",
       "   [2, 205, 32, 112, 173, 231, 0, 0],\n",
       "   [2, 215, 31, 109, 160, 227, 242, 0],\n",
       "   [2, 215, 10, 112, 150, 223, 238, 0],\n",
       "   [3, 207, 27, 95, 159, 232, 241, 261],\n",
       "   [2, 210, 30, 113, 149, 233, 0, 244],\n",
       "   [3, 209, 36, 103, 157, 225, 242, 261],\n",
       "   [2, 206, 28, 109, 173, 230, 0, 261],\n",
       "   [3, 218, 34, 111, 154, 234, 238, 261],\n",
       "   [2, 206, 13, 92, 166, 220, 239, 0],\n",
       "   [2, 196, 36, 113, 143, 222, 0, 244],\n",
       "   [2, 214, 11, 111, 162, 223, 243, 0],\n",
       "   [2, 196, 24, 111, 150, 220, 0, 261],\n",
       "   [2, 204, 43, 105, 126, 229, 240, 0],\n",
       "   [3, 194, 19, 114, 130, 230, 240, 261],\n",
       "   [2, 212, 52, 114, 175, 226, 241, 0],\n",
       "   [2, 209, 31, 115, 126, 226, 243, 244],\n",
       "   [2, 207, 18, 99, 183, 225, 243, 244],\n",
       "   [2, 195, 41, 114, 175, 228, 0, 0],\n",
       "   [2, 204, 35, 113, 180, 229, 0, 244],\n",
       "   [2, 191, 38, 92, 153, 221, 240, 244],\n",
       "   [2, 212, 71, 104, 132, 232, 240, 244],\n",
       "   [2, 198, 43, 97, 147, 225, 0, 261],\n",
       "   [3, 195, 17, 96, 144, 229, 243, 261],\n",
       "   [2, 209, 33, 98, 179, 229, 0, 261],\n",
       "   [2, 217, 43, 111, 184, 233, 0, 261],\n",
       "   [3, 194, 9, 115, 157, 234, 243, 261],\n",
       "   [2, 197, 28, 109, 145, 229, 0, 0],\n",
       "   [2, 213, 60, 94, 155, 234, 243, 0],\n",
       "   [2, 197, 87, 105, 164, 230, 239, 244],\n",
       "   [2, 210, 24, 108, 173, 230, 0, 244],\n",
       "   [2, 195, 41, 115, 172, 221, 239, 0],\n",
       "   [2, 198, 34, 113, 127, 223, 0, 0],\n",
       "   [2, 209, 38, 101, 159, 225, 0, 261],\n",
       "   [2, 210, 24, 91, 137, 226, 0, 0],\n",
       "   [2, 209, 30, 116, 169, 228, 0, 0],\n",
       "   [2, 190, 26, 118, 152, 220, 239, 261],\n",
       "   [2, 207, 35, 97, 153, 223, 0, 244],\n",
       "   [3, 188, 30, 106, 176, 228, 240, 261],\n",
       "   [3, 200, 85, 105, 161, 222, 240, 261],\n",
       "   [2, 191, 30, 110, 161, 225, 243, 0],\n",
       "   [2, 211, 29, 110, 171, 223, 0, 261],\n",
       "   [2, 215, 25, 118, 171, 229, 0, 261],\n",
       "   [2, 193, 28, 108, 155, 225, 241, 261],\n",
       "   [2, 214, 43, 110, 145, 221, 240, 261],\n",
       "   [2, 0, 62, 117, 180, 226, 239, 261],\n",
       "   [2, 218, 72, 94, 182, 229, 242, 261],\n",
       "   [2, 210, 41, 114, 184, 0, 243, 244],\n",
       "   [2, 190, 49, 98, 140, 225, 243, 261],\n",
       "   [2, 209, 32, 110, 162, 226, 243, 261],\n",
       "   [2, 219, 33, 118, 148, 231, 0, 0],\n",
       "   [2, 188, 27, 109, 159, 234, 0, 0],\n",
       "   [2, 205, 38, 108, 140, 222, 0, 261],\n",
       "   [3, 198, 45, 103, 145, 224, 242, 261],\n",
       "   [2, 187, 7, 109, 125, 233, 240, 244],\n",
       "   [2, 214, 24, 115, 157, 229, 240, 0],\n",
       "   [2, 194, 32, 109, 153, 229, 0, 0],\n",
       "   [2, 211, 36, 114, 160, 231, 0, 0],\n",
       "   [2, 212, 35, 117, 182, 0, 0, 244],\n",
       "   [2, 0, 14, 107, 180, 220, 239, 261],\n",
       "   [2, 187, 32, 103, 158, 234, 242, 244],\n",
       "   [2, 210, 84, 98, 130, 228, 0, 244],\n",
       "   [2, 206, 20, 117, 184, 224, 243, 0],\n",
       "   [3, 193, 31, 108, 152, 220, 243, 261],\n",
       "   [2, 215, 27, 117, 137, 0, 0, 244],\n",
       "   [3, 196, 0, 91, 175, 232, 242, 261],\n",
       "   [3, 216, 52, 93, 142, 225, 243, 261],\n",
       "   [2, 0, 28, 110, 161, 225, 0, 261],\n",
       "   [2, 216, 39, 118, 133, 0, 0, 244],\n",
       "   [2, 211, 38, 112, 153, 220, 0, 261],\n",
       "   [2, 208, 58, 111, 168, 232, 241, 0],\n",
       "   [2, 205, 46, 98, 152, 233, 242, 261],\n",
       "   [2, 201, 63, 110, 137, 231, 241, 0],\n",
       "   [2, 213, 11, 113, 170, 232, 238, 261],\n",
       "   [3, 212, 30, 94, 128, 224, 238, 261],\n",
       "   [2, 196, 25, 110, 158, 224, 238, 261],\n",
       "   [2, 201, 28, 112, 148, 0, 0, 0],\n",
       "   [2, 215, 42, 109, 147, 0, 0, 0],\n",
       "   [2, 193, 85, 90, 156, 0, 242, 244],\n",
       "   [2, 205, 32, 94, 156, 232, 240, 244],\n",
       "   [3, 199, 71, 93, 132, 226, 241, 261],\n",
       "   [2, 194, 33, 91, 135, 227, 241, 261],\n",
       "   [2, 0, 28, 102, 142, 226, 241, 0],\n",
       "   [2, 205, 27, 111, 136, 223, 0, 261],\n",
       "   [2, 201, 35, 113, 171, 233, 0, 261],\n",
       "   [2, 208, 28, 97, 130, 234, 0, 0],\n",
       "   [2, 207, 32, 115, 154, 230, 0, 0],\n",
       "   [2, 214, 29, 96, 143, 227, 0, 0],\n",
       "   [3, 193, 32, 109, 146, 230, 238, 261],\n",
       "   [3, 203, 64, 97, 183, 223, 240, 261],\n",
       "   [2, 201, 29, 119, 136, 222, 238, 261],\n",
       "   [2, 206, 18, 102, 174, 229, 243, 0],\n",
       "   [3, 213, 39, 104, 186, 224, 243, 261],\n",
       "   [2, 203, 35, 111, 178, 229, 243, 0],\n",
       "   [2, 204, 40, 110, 182, 228, 0, 0],\n",
       "   [2, 206, 24, 109, 152, 233, 0, 261],\n",
       "   [2, 218, 42, 111, 173, 221, 243, 0],\n",
       "   [2, 195, 24, 117, 145, 231, 241, 244],\n",
       "   [2, 193, 69, 100, 135, 220, 239, 261],\n",
       "   [2, 201, 71, 113, 144, 234, 240, 261],\n",
       "   [2, 219, 15, 94, 144, 220, 241, 261],\n",
       "   [2, 1, 79, 93, 146, 232, 241, 244],\n",
       "   [2, 206, 34, 115, 172, 231, 243, 261],\n",
       "   [3, 197, 27, 113, 151, 225, 243, 261],\n",
       "   [2, 218, 42, 119, 126, 223, 242, 244],\n",
       "   [2, 192, 27, 93, 131, 220, 0, 0],\n",
       "   [2, 193, 31, 110, 152, 234, 242, 261],\n",
       "   [2, 198, 43, 118, 137, 232, 239, 0],\n",
       "   [2, 204, 72, 94, 129, 221, 0, 261],\n",
       "   [2, 215, 47, 92, 182, 228, 238, 0],\n",
       "   [2, 212, 15, 98, 131, 229, 241, 261],\n",
       "   [2, 214, 47, 96, 140, 234, 241, 261],\n",
       "   [2, 212, 69, 97, 162, 232, 242, 261],\n",
       "   [2, 207, 27, 103, 185, 225, 0, 261],\n",
       "   [2, 187, 34, 115, 154, 221, 0, 261],\n",
       "   [2, 199, 30, 118, 123, 233, 0, 0],\n",
       "   [2, 205, 25, 117, 176, 228, 0, 0],\n",
       "   [2, 216, 33, 115, 177, 223, 0, 244],\n",
       "   [2, 215, 40, 118, 143, 229, 0, 0],\n",
       "   [2, 203, 32, 112, 148, 232, 0, 0],\n",
       "   [2, 212, 34, 102, 127, 234, 0, 0],\n",
       "   [2, 218, 13, 102, 144, 229, 243, 261],\n",
       "   [2, 188, 64, 109, 160, 229, 241, 0],\n",
       "   [3, 201, 87, 108, 178, 233, 243, 261],\n",
       "   [2, 214, 26, 110, 145, 222, 0, 261],\n",
       "   [2, 197, 34, 110, 144, 226, 0, 244],\n",
       "   [2, 0, 66, 114, 127, 226, 0, 244],\n",
       "   [2, 191, 38, 115, 123, 228, 0, 261],\n",
       "   [2, 219, 62, 96, 158, 225, 241, 0],\n",
       "   [2, 210, 24, 112, 159, 230, 0, 0],\n",
       "   [2, 212, 27, 114, 141, 234, 0, 261],\n",
       "   [2, 216, 43, 90, 171, 228, 0, 244],\n",
       "   [2, 212, 58, 91, 134, 234, 240, 261],\n",
       "   [2, 203, 32, 109, 170, 233, 243, 261],\n",
       "   [3, 189, 23, 106, 149, 234, 239, 261],\n",
       "   [2, 198, 8, 115, 152, 234, 242, 244],\n",
       "   [2, 206, 45, 104, 155, 225, 243, 244],\n",
       "   [3, 213, 18, 108, 179, 222, 242, 261],\n",
       "   [2, 209, 34, 114, 166, 225, 0, 0],\n",
       "   [2, 207, 35, 96, 184, 220, 241, 261],\n",
       "   [2, 189, 65, 115, 173, 226, 239, 244],\n",
       "   [2, 188, 41, 108, 130, 230, 241, 261],\n",
       "   [2, 212, 26, 116, 153, 0, 0, 261],\n",
       "   [2, 190, 34, 96, 154, 228, 0, 0],\n",
       "   [2, 189, 41, 110, 177, 224, 0, 244],\n",
       "   [2, 210, 28, 112, 149, 234, 0, 0],\n",
       "   [2, 213, 54, 106, 183, 223, 240, 261],\n",
       "   [2, 216, 9, 97, 185, 227, 241, 261],\n",
       "   [2, 0, 12, 109, 159, 232, 239, 261],\n",
       "   [2, 211, 14, 109, 149, 224, 238, 244],\n",
       "   [3, 212, 33, 109, 151, 223, 243, 261],\n",
       "   [2, 218, 33, 108, 138, 220, 243, 261]]]]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "25eeccc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp_transgan_wgan_gp_final_15_04_1.mid\n",
      "cp_transgan_wgan_gp_final_15_04_2.mid\n",
      "cp_transgan_wgan_gp_final_15_04_3.mid\n",
      "cp_transgan_wgan_gp_final_15_04_4.mid\n"
     ]
    }
   ],
   "source": [
    "date = '15_04_'\n",
    "pitch_ranges = []\n",
    "n_pitches = []\n",
    "polyphonies = []\n",
    "empty_beat_rates = []\n",
    "for i,seq in enumerate(sequences):\n",
    "    # TODO: remove this\n",
    "    # seq = seq[0]\n",
    "\n",
    "    converted_back_midi = cp_enc.tokens_to_midi(seq, get_midi_programs(midi))\n",
    "    file_name = 'cp_transgan_wgan_gp_final_' + date  + str(i+1) + '.mid'\n",
    "    converted_back_midi.dump(file_name)\n",
    "    music = muspy.read_midi(file_name)\n",
    "    pitch_range = muspy.pitch_range(music)\n",
    "    n_pitches_used = muspy.n_pitches_used(music)\n",
    "    polyphony = muspy.polyphony(music) # average number of pitches being played concurrently.\n",
    "    empty_beat_rate = muspy.empty_beat_rate(music)\n",
    "\n",
    "    # music = muspy.read_midi(file_name)\n",
    "    pitch_ranges.append(muspy.pitch_range(music))\n",
    "    n_pitches.append(muspy.n_pitches_used(music))\n",
    "    polyphonies.append(muspy.polyphony(music)) # average number of pitches being played concurrently.\n",
    "    empty_beat_rates.append(muspy.empty_beat_rate(music))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "41f862a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_transgan = {'Pitch_range': pitch_ranges, 'Num_pitches': n_pitches, 'Polyphony': polyphonies, 'Empty_beat_rates': empty_beat_rates}\n",
    "results_df = pd.DataFrame(results_transgan)\n",
    "results_df.to_csv('remi_ransgan_results_v2_emo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c8a9f99c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T19:56:49.918349Z",
     "iopub.status.busy": "2022-02-02T19:56:49.917802Z",
     "iopub.status.idle": "2022-02-02T19:56:49.924542Z",
     "shell.execute_reply": "2022-02-02T19:56:49.923850Z",
     "shell.execute_reply.started": "2022-02-02T19:56:49.918312Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticks per beat: 384\n",
       "max tick: 0\n",
       "tempo changes: 1\n",
       "time sig: 0\n",
       "key sig: 0\n",
       "markers: 0\n",
       "lyrics: False\n",
       "instruments: 1"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted_back_midi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390772d9",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a90ecba",
   "metadata": {},
   "source": [
    "### BLEU Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f1939c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smoothing_function=SmoothingFunction().method1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03e1042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10372, 101])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_check = train_data[:,:,0]\n",
    "train_check.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87da4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_check = []\n",
    "for sequence in sequences:\n",
    "    # print(sequence[0])\n",
    "    for i in range(0, len(sequence[0])-101, 101):\n",
    "        gen_check.append(sequence[0][i:i+101])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37810c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([156, 101])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(gen_check).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0c0c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "score = corpus_bleu([train_check], [torch.Tensor(gen_check)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b03ba9",
   "metadata": {},
   "source": [
    "### MusPy metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bb5620bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pitch_range</th>\n",
       "      <th>Num_pitches</th>\n",
       "      <th>Polyphony</th>\n",
       "      <th>Empty_beat_rates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>81.5</td>\n",
       "      <td>62.750000</td>\n",
       "      <td>25.283782</td>\n",
       "      <td>0.008333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.707825</td>\n",
       "      <td>5.285152</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>81.0</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>17.424107</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>81.0</td>\n",
       "      <td>61.750000</td>\n",
       "      <td>24.606027</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>81.0</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>27.516667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>81.5</td>\n",
       "      <td>63.500000</td>\n",
       "      <td>28.194421</td>\n",
       "      <td>0.008333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>83.0</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>28.677686</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pitch_range  Num_pitches  Polyphony  Empty_beat_rates\n",
       "count          4.0     4.000000   4.000000          4.000000\n",
       "mean          81.5    62.750000  25.283782          0.008333\n",
       "std            1.0     1.707825   5.285152          0.016667\n",
       "min           81.0    61.000000  17.424107          0.000000\n",
       "25%           81.0    61.750000  24.606027          0.000000\n",
       "50%           81.0    62.500000  27.516667          0.000000\n",
       "75%           81.5    63.500000  28.194421          0.008333\n",
       "max           83.0    65.000000  28.677686          0.033333"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2579f5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "music = muspy.read_midi('conditioned_17_03_4.mid')\n",
    "pitch_range = muspy.pitch_range(music)\n",
    "n_pitches_used = muspy.n_pitches_used(music)\n",
    "polyphony = muspy.polyphony(music) # average number of pitches being played concurrently.\n",
    "empty_beat_rate = muspy.empty_beat_rate(music)\n",
    "\n",
    "print(\"The pitch range is\", pitch_range)\n",
    "print(\"The number of unique pitches used is\", n_pitches_used)\n",
    "print(\"The polyphony is\", polyphony)\n",
    "print(\"The empty beat rate is\", empty_beat_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10226242",
   "metadata": {},
   "source": [
    "## Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7262be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MidiBert(nn.Module):\n",
    "    def __init__(self, bert_model_path, ntokens, hidden_size=200):\n",
    "        super().__init__()\n",
    "        \n",
    "        # self.bert = BertModel(max_position_embeddings= max_position_embeddings, position_embedding_type=position_embedding_type, hidden_size=hidden_size)\n",
    "        self.bert = BertForSequenceClassification.from_pretrained(bert_model_path, problem_type=\"multi_label_classification\", num_labels = 4)\n",
    "        self.d_model = 768\n",
    "        self.hidden_size = hidden_size\n",
    "        # self.bertConfig = bertConfig\n",
    "\n",
    "        # token types: [Bar, Position, Pitch, Duration]\n",
    "        self.n_token = ntokens\n",
    "        self.emb_size = 256\n",
    "        \n",
    "        # word_emb: embeddings to change token ids into embeddings\n",
    "        self.word_emb = nn.Embedding(self.n_token, self.emb_size) \n",
    "\n",
    "        # linear layer to merge embeddings from different token types \n",
    "        self.in_linear = nn.Linear(self.emb_size, self.d_model)\n",
    "\n",
    "        self.proj = nn.Linear(hidden_size, ntokens)\n",
    "\n",
    "\n",
    "    def forward(self, input_id, attn_mask=None):\n",
    "        # convert input_ids into embeddings and merge them through linear layer\n",
    "        emb = self.word_emb(input_id) * math.sqrt(self.d_model)\n",
    "        # emb_squared = emb \n",
    "        emb_linear = self.in_linear(emb)\n",
    "        \n",
    "        # feed to bert \n",
    "        y = self.bert(inputs_embeds=emb_linear, attention_mask=attn_mask, output_hidden_states=True)\n",
    "        # y = y.hidden_states[-1]        # (batch_size, seq_len, 768)\n",
    "        # y = self.proj(y) \n",
    "        return y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 106.840771,
   "end_time": "2022-02-02T19:59:15.470216",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-02T19:57:28.629445",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
